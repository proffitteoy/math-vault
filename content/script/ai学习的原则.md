我们现在本科低年级学习的许多数学知识，一两百年前往往只有博士生才能涉猎。这当然并非因为人类的DNA在过去一百年里发生了突变而是因为学习这些知识的信息差被大幅缩小了。

例如，微积分这门学科，从牛顿的原始手稿、到欧拉的《无穷小量分析》，再到布尔巴基学派的系统化革新，以及现如今丰富多样的教材。在此过程中，微积分本身并未变得更简单（事实上，我们现在学到的内容往往更深入、更复杂），而是学习时的障碍被不断移除，误入歧途的可能性大大降低。

毫无疑问，如今的生成式AI可以有效降低学习中的信息差。以学习外语为例，过去要学好一门外语，往往需要请外教帮助练习口语、指导写作、解释句意，而现在这些功能AI都能胜任。

目前的AI并未真正“理解”人类知识，而一些专业领域对错误的容忍相对其他领域更低。因此，直接采信AI的回答，可能面临被误导的风险，带来额外的时间成本和错误后果。

当然，AI在解决某些数学问题上仍具潜力，因此完全忽视这种新工具并不明智。下面，我将结合自身使用生成式AI的经验，分享一些在学习中使用AI的“原则”。

### 1. 使用AI学习的原则
#### 1.1 核心原则

> [!note] 使用LLM式的AI的核心原则
> 只问AI擅长的回答的问题。

既然每次人机对话都有可能带来收益，也可能产生损失，这不禁让人联想到期货交易员的“交易原则”。在期货市场中，每次交易都有风险，同样也有盈利的机会。那么，交易与赌博的区别何在？

> [!note] 交易与赌博的区别
> 交易是只在对自己有利的局面进行博弈，而赌博是只在对庄家有利的局面下进行博弈。

理论上，如果在与AI的互动中，我们能够识别AI在哪些类型的问题上表现良好、哪些类型上容易出错，那么就应仅向AI提问它擅长的内容，从而将损失控制在可接受范围内，使得整体受益。
#### 1.2 容错与验证难度原则
要界定AI是否适合回答某个问题，我们需要在提问之前评估以下关键指标（参考自[陶在mastodon上的贴文](https://mathstodon.xyz/@tao/114246467132630996)）：

> [!note] 容错与验证难度原则
> 只有在我们对回答的当中错误的容忍度较高，且回答的正确性容易被验证的情况下才参考AI的回答。

> [!example] 例子：借助AI写程序
> 我曾多次使用ai写代码，编程不像我熟悉的数学领域，他的很多基础语法非常复杂，要纯人工的完成一个命题或者说构建什么东西都非常费时费力，但我又无法花费太多的精力脱离数学学习去完成他，因此我常常通过ai来帮助我快速拿到一些我需要的结果。
> 在这个任务当中：
> 1. 容错度高：若纯手动实现，可能需要耗费数天时，因此与 AI 协作将整体耗时压缩至一小时，让我非常满意。
> 2. 验证难度低：即便 AI 生成的代码初次无法通过，我也能根据报错信息定位并修正
> 

### 2. 不能让AI代替我们学习

[Your Brain on ChatGPT: Accumulation of Cognitive Debt when Using an AI Assistant for Essay Writing Task](https://arxiv.org/pdf/2506.08872)这篇文章提到一个概念称之为“认知负债(cognitive debt)”，指的是：
当工具代替我们大脑去完成一些认识任务的时候，短期看似乎效率得到了提升，但长期则像是滚雪球一样侵蚀我们的注意力，记忆力以及元认知能力。
这个实验给到我们的启发是：
当我们把本应由大脑完成的推理大量外包给 LLM 时，短期似乎省时省力，但长期却会逐渐削弱注意力、记忆力与元认知能力。大脑学习中：真正能够激发神经可塑性的，是落在“黄金区”的适度负荷（就想象一下你去健身，举重的时候不能选那种上来就压死你的哑铃也不能拿羽毛进行举重练习）
所以我们应该先自己独立思考，在进行了充分的思考以后再借助AI工具的辅助，这样才能达到更好的学习效果。
