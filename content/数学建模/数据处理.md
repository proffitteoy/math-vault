
核心逻辑链条可以总结为一句话：

 **从原始数据 → 清洗（质量）→ 变换（尺度、分布）→ 特征表达（结构）→ 假设检验（可信性）→ 模型指标（可比较性）。**


# **1. 标准化与数据变换（Normalization & Transformation）**

### **核心思想**

使变量具有统一尺度、形态可控，使模型更稳定、更易训练。

### **背后模型依赖**

* 线性模型依赖尺度一致性（避免某特征权重过大）
* 距离类算法（kNN、k-means、DBSCAN）强依赖尺度
* 深度网络训练依赖稳定梯度分布

### **常用方法**

* Z-score 标准化
* Min-max 缩放
* Box-Cox / Yeo-Johnson 变换
* 对数 / 幂变换
* 分位数归一化（常见于非高斯分布）


# **2. 插值**

### **核心思想**

在离散采样点之间重建连续函数，使模型能利用完整连续信息。

### **典型形态**

* 多项式插值
* 样条插值（Cubic Spline）

### **应用场景**

* 时间序列缺失点填补
* 实验数据光滑化
* 数据补点


# **3. 假设检验（Hypothesis Testing）**

### **核心思想**

判断数据中观察到的模式是否具有统计意义，而非随机波动。

### **典型内容**

* t 检验 / Mann–Whitney
* χ² 检验
* KS 检验（判断分布形状）
* A/B test 框架
* p-value、置信区间解释

### **为什么重要**
* 作为“是否能用某方法”的依据（如是否满足正态分布假设）。


# **4. 熵权法（Entropy Weight Method）**

### **核心思想**

用信息熵衡量变量“不确定性—有效信息量”，从而给特征自动赋权。

### **本质**

* 方差大 → 信息量大 → 权重高
* 方差小 → 区分度弱 → 权重低


# **5. 数据分布拟合（Distribution Fitting）**

### **核心思想**

用概率分布刻画数据的生成机制 → 为后续统计推断、模拟、极值分析等铺路。

### **方法**

* 拟合参数分布（正态、对数正态、Gamma、Weibull）
* 使用 AIC/BIC 选择模型
* 非参数分布（核密度估计 KDE）

### **联系**

* 为假设检验提供分布
* 为蒙特卡洛模拟提供随机源
* 为极值建模（GPD, EVT）奠定基础


# **6. 数据共线性（Multicollinearity）**

### **核心思想**

当多个特征高度相关时 → 线性模型的估计不稳定、方差爆炸。

### **典型方法**

* VIF（方差膨胀因子）
* Condition Number
* 岭回归 / Lasso 缓解共线性
* PCA 消除冗余维度

### **为什么重要**

你在建模时所有“回归”“拟合”相关模型，都严重依赖低共线性。


# **7. 数据预处理（Data Cleaning & Preparation）**

### **核心思想**

解决“不干净的数据”，保证模型输入正确、分布稳定。

### **步骤结构化表达**

1. 缺失值处理（插值、建模、删除）
2. 异常值识别（z-score、IQR、LOF）
3. 一致化（单位、编码、格式）
4. 分箱、哑变量、时间特征拆分
5. 数据泄漏检查

### **联系**

这是整个建模管线中最关键、最消耗时间的部分。


# **8. 算法指标（Model Metrics）**

### **核心思想**

不同问题用不同评价准则，用指标衡量模型是否“好”。

### **分类任务**

* Accuracy
* Precision/Recall/F1
* ROC-AUC
* PR-AUC

### **回归任务**

* RMSE
* MAE
* R²

### **无监督任务**

* 轮廓系数（Silhouette）
* Calinski-Harabasz
* Dunn index

### **为什么重要**

你必须通过指标指导你选择模型、调参、最终比较方案。

# **9. 特征选择与相关性分析（Feature Selection & Correlation Analysis）**

### **核心思想**

减少冗余变量、提升模型泛化能力。

### **相关性分析**

* Pearson / Spearman
* MI（互信息）
* Kendall τ
* 皮尔逊相关热图

### **特征选择三类方法**

1. **Filter**：相关性、方差、卡方、MI
2. **Wrapper**：RFE、前向/后向选择
3. **Embedded**：Lasso、树模型特征重要性

### **联系**

共线性检测 → 特征选择 → 变量标准化
三者构成“建模前特征工程”的完整闭环。


# **整个数据处理体系的核心结构图**

```
原始数据
   ↓ 清洗（质量）
   ↓ 预处理（缺失、异常、编码）
   ↓ 变换（标准化、归一化、分布变换）
   ↓ 特征结构化（插值、分箱、构造变量）
   ↓ 统计检验（是否可信、分布是否合理）
   ↓ 特征选择（相关性、VIF、MI）
   ↓ 数据分布建模（用于模拟与假设检验）
   ↓ 输出建模（模型输入接口）
   ↓ 指标衡量（反馈闭环）
```

---
直接看官方文档：
---
https://docs.scipy.org/doc/scipy/tutorial/interpolate.html
---
https://scikit-learn.org/stable/index.html