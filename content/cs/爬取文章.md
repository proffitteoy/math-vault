
# 从爬取动态网页到反爬设计的完整认知框架

> [!tip]
> Tracking 链接可通过 MIME + 响应特征完全排除；  
> Burp 的作用是确认渲染来源，而非抓取数据；  
> 反爬即封锁爬虫曾经走通的路径，  
> 强化成本直至逆向成为唯一通路。


### 一 **Burp Suite溯源**

Burp 承担的核心能力是——**区分静态渲染与动态加载**。
**它的价值不是抓文章，而是回答一个问题：文章是从哪里来的？**

| 观察指标                         | 结论              |
| ---------------------------- | --------------- |
| History 中无 XHR / Fetch 返回正文  | 内容非异步拉取         |
| HTML 主文档可直接看到骨架容器 `.tx-text` | 来源即页面本身         |
| 页面加载延迟来自 JS 渲染而非接口响应         | Selenium 可复现呈现态 |

Burp 在此扮演 **信息源定位器**，**数据供应链分析工具**。  
作用是确认路径，而不是执行获取。

### 二 **误导链接的定性与识别机制**
 `sp0.baidu.com/.../s.gif` 本质是 **Tracking Pixel**，用于收录、统计或行为跟踪，并不承载文章内容。
 
其识别关键特征并不依赖经验，而是基于协议分析：

**MIME = image/gif** → 非数据载体**响应体极小（几字节**→ 不可能包含文章**URL 结构携带目标页面作为参数而非资源路径** → 反向指向型，不是内容源


### 三 分析流程
是一个不带任何混淆和反爬的网页，直接写脚本拼接各个部分文章：
```python
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
import time

url = ""

options = Options()
options.add_argument("--headless")
options.add_argument("--disable-gpu")
driver = webdriver.Chrome(options=options)
driver.get(url)
time.sleep(3)  # 等待 JS 渲染文章
# 抓取 .tx-text 内所有元素

elements = driver.find_elements("css selector", ".tx-text *")
article = "\n\n".join([e.text.strip() for e in elements if e.text.strip()])
print(article)
driver.quit()
```
### 四 可能的反爬策略改进

>[!note]
> **页面不持有明文，JS 不持久储存密钥，正文依 API 分段加密返回**  
> ——攻方必须逆协议、逆JS、重组、解密。  
> 此时抓取成本与逆向成本趋近。

| 爬虫突破点               | 对应反爬策略                        |
| ------------------- | ----------------------------- |
| Requests 无门槛访问      | Header 校验、UA 绑定、Cookie 验证     |
| Selenium 模拟浏览器渲染    | 检测 `navigator.webdriver`、指纹校验 |
| 直接读取 `.tx-text` DOM | DOM碎片化/随机化/延迟插入               |
| 无需接口，仅HTML组件拼接      | 正文API化+加密传输+动态密钥分发            |


